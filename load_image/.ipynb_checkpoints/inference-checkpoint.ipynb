{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ae2d30-ae6b-4a84-ac3c-e9865c4b0d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2a77ddcc784a0aab15fc297fbb5b15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Device:', index=1, options=('CPU', 'AUTO'), value='AUTO')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# Instantiate procedure OpenVINO Core\n",
    "core = ov.Core()\n",
    "device = widgets.Dropdown(\n",
    "    options=core.available_devices + [\"AUTO\"],\n",
    "    value=\"AUTO\",\n",
    "    description=\"Device:\",\n",
    "    disabled=False,\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6093e7-feab-482a-8000-9af78502b1ba",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31007503-5cd3-42c3-85bc-fb7da2665fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_modulo = 64\n",
    "def pad_image(image):\n",
    "    h, w, c = image.shape\n",
    "    # Add pad value to make sure the size of image is the same as size of input\n",
    "    # This\n",
    "    pad_h = int(np.ceil(h/padding_modulo)*padding_modulo-h)\n",
    "    pad_w = int(np.ceil(w/padding_modulo)*padding_modulo-w)    \n",
    "    padded_image = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), \n",
    "                          mode='constant', \n",
    "                          constant_values=0)\n",
    "\n",
    "def unpad_image(image, pad_h, pad_w):\n",
    "    return image[:-pad_h, :-pad_w, :] if pad_h > 0 and pad_w > 0 else image\n",
    "    \n",
    "def normalize(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the image to the given mean and standard deviation\n",
    "    for CityScapes models.\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    image /= 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def postprocess_image(output_array):\n",
    "    output_array = np.clip(output_array, 0, 1)  # Ensure the values are within [0, 1]\n",
    "    output_array = (output_array * 255).astype(np.uint8)  # Denormalize the image\n",
    "    output_image = Image.fromarray(output_array)\n",
    "    return output_image\n",
    "\n",
    "def show_image(img_path, cmap=None):\n",
    "    '''Show image '''\n",
    "    # plt.close('all')\n",
    "    data = cv2.imread(img_path)\n",
    "    plt.imshow(data, cmap=cmap)\n",
    "    plt.show()\n",
    "    return np.asarray(data)\n",
    "def digest_input(img_path):\n",
    "    '''\n",
    "    # input digestion\n",
    "    Ex: \n",
    "    img_path = 'input.jpg'\n",
    "    normalized_input_image = digest_input(img_path)\n",
    "    '''    \n",
    "    image = cv2.imread(img_path)\n",
    "    # Convert BGR to RGB \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # (1088, 1920, 3)\n",
    "    ## Preprocess \n",
    "    # Normalize in range (0;1)\n",
    "    image = np.array(image).astype(np.float32) / 255.0  # Normalize the image\n",
    "    # # Resize  \n",
    "    # original_height, original_width = image.shape[:2]\n",
    "    # padded_image, pad_h, pad_w = pad_image(image)\n",
    "    ## Feed into network\n",
    "    # Convert to CHW format\n",
    "    input_image = np.transpose(image, (2, 0, 1)) # (1088, 1920, 3) --> (3,1088,1920)\n",
    "    # Expand dimensions for the network\n",
    "    normalized_input_image = np.expand_dims(input_image, 0)# --> (1,3,1088,1920)\n",
    "    return normalized_input_image\n",
    "\n",
    "def restructure_image(predicted_tensor):\n",
    "    '''\n",
    "    output_image = restructure_imgae(res_onnx[0])\n",
    "    '''\n",
    "    # Remove batch dimension \n",
    "    # (1,3,1088,1920)-> (3,1088,1920)\n",
    "    output_image = np.squeeze(predicted_tensor, axis=0)  \n",
    "    #(3,1088,1920) -> (1088, 1920, 3)\n",
    "    output_image = np.transpose(output_image, (1, 2, 0))  # Convert to HWC format\n",
    "    # Post process\n",
    "    output_image = postprocess_image(output_image)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c4fb8-23e9-4b2c-8699-339002415173",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6f4c98-aa8e-4dd4-8dec-fea269cbd8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'input_1.jpg'\n",
    "normalized_input_image = digest_input(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c14fe1-e322-49ff-bea9-b37c1c49cbe2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Onnx inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab301795-93a8-4330-b372-8c6620cfc4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME: 0.743027925491333\n"
     ]
    }
   ],
   "source": [
    "onnx_path = 'convnext-tiny-llie-sim.onnx'\n",
    "# Read model to OpenVINO Runtime\n",
    "model_onnx = core.read_model(model=onnx_path)\n",
    "# Load model on device\n",
    "compiled_model_onnx = core.compile_model(model=model_onnx, device_name=device.value)\n",
    "\n",
    "# Run inference on the input image\n",
    "start = time.time()\n",
    "res_onnx = compiled_model_onnx([normalized_input_image])\n",
    "end = time.time()\n",
    "print(f\"TOTAL TIME: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae26e026-4679-4004-b85a-dee9ec3bc447",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = restructure_image(res_onnx[0])\n",
    "output_path = 'output_onnx_sim.jpg'\n",
    "output_image.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a060b-108c-4da7-b273-689a2f29d63e",
   "metadata": {},
   "source": [
    "# Vivo inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a91a791b-28ca-437b-81c1-b461e4d26e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME: 0.07840323448181152\n",
      "TOTAL TIME: 0.07111191749572754\n",
      "TOTAL TIME: 0.06215095520019531\n",
      "TOTAL TIME: 0.0729210376739502\n",
      "TOTAL TIME: 0.0770866870880127\n"
     ]
    }
   ],
   "source": [
    "ir_path = 'models/reseffnet_gan_div4.xml'\n",
    "core = ov.Core()\n",
    "model_ir = core.read_model(model=ir_path)\n",
    "compiled_model_ir = core.compile_model(model=model_ir, device_name=device.value)\n",
    "\n",
    "# # Get input and output layers.\n",
    "# output_layer_ir = compiled_model_ir.output(0)\n",
    "\n",
    "# # Run inference on the input image.\n",
    "# res_ir = compiled_model_ir([normalized_input_image])[output_layer_ir]\n",
    "\n",
    "# Run inference on the input image\n",
    "for i in range(5):\n",
    "    start = time.time()\n",
    "    res_ir = compiled_model_ir([normalized_input_image])\n",
    "    end = time.time()\n",
    "    print(f\"TOTAL TIME: {end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "129e773f-681f-4453-a86c-0b91e59bc884",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = restructure_image(res_ir[0])\n",
    "output_path = 'output_py_1.jpg'\n",
    "output_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd9abae-0f9c-4698-a2d6-c562830f5e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: 11th Gen Intel(R) Core(TM) i7-11390H @ 3.40GHz\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "devices = core.available_devices\n",
    "for device in devices:\n",
    "    device_name = core.get_property(device, \"FULL_DEVICE_NAME\")\n",
    "    print(f\"{device}: {device_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66d24701-f698-499a-b576-cdfc2f3e1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CompiledModel:\n",
      "inputs[\n",
      "<ConstOutput: names[input] shape[1,3,1088,1920] type: f32>\n",
      "]\n",
      "outputs[\n",
      "<ConstOutput: names[output] shape[1,3,1088,1920] type: f32>\n",
      "]>\n"
     ]
    }
   ],
   "source": [
    "print(compiled_model_ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d3cd4-b790-435c-a65b-d1e275712493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
