{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "934295a5-baf8-4e8b-8c54-94b837c0b419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import warnings\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eabe1001-eb64-4d35-9c39-84dd5762d8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_modulo = 64\n",
    "def pad_image(image):\n",
    "    h, w, c = image.shape\n",
    "    # Add pad value to make sure the size of image is the same as size of input\n",
    "    # This\n",
    "    pad_h = int(np.ceil(h/padding_modulo)*padding_modulo-h)\n",
    "    pad_w = int(np.ceil(w/padding_modulo)*padding_modulo-w)    \n",
    "    padded_image = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), \n",
    "                          mode='constant', \n",
    "                          constant_values=0)\n",
    "\n",
    "def unpad_image(image, pad_h, pad_w):\n",
    "    return image[:-pad_h, :-pad_w, :] if pad_h > 0 and pad_w > 0 else image\n",
    "    \n",
    "def normalize(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Normalize the image to the given mean and standard deviation\n",
    "    for CityScapes models.\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float32)\n",
    "    mean = (0.485, 0.456, 0.406)\n",
    "    std = (0.229, 0.224, 0.225)\n",
    "    image /= 255.0\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image\n",
    "\n",
    "def postprocess_image(output_array):\n",
    "    output_array = np.clip(output_array, 0, 1)  # Ensure the values are within [0, 1]\n",
    "    output_array = (output_array * 255).astype(np.uint8)  # Denormalize the image\n",
    "    output_image = Image.fromarray(output_array)\n",
    "    return output_image\n",
    "\n",
    "def show_image(img_path, cmap=None):\n",
    "    '''Show image '''\n",
    "    # plt.close('all')\n",
    "    data = cv2.imread(img_path)\n",
    "    plt.imshow(data, cmap=cmap)\n",
    "    plt.show()\n",
    "    return np.asarray(data)\n",
    "def digest_input(img_path):\n",
    "    '''\n",
    "    # input digestion\n",
    "    Ex: \n",
    "    img_path = 'input.jpg'\n",
    "    normalized_input_image = digest_input(img_path)\n",
    "    '''    \n",
    "    image = cv2.imread(img_path)    \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # (880, 480, 3) # (w,h,c) \n",
    "    height, width, channels = image.shape    \n",
    "    new_size = (480 , 270)  # Width, Height\n",
    "    image = cv2.resize(image, new_size, interpolation=cv2.INTER_LINEAR) # (270, 480, 3)\n",
    "    cv2.imwrite('resized_image.jpg', image)\n",
    "    ## Preprocess \n",
    "    # Normalize in range (0;1)\n",
    "    image = np.array(image).astype(np.float32) / 255.0  # Normalize the image      \n",
    "    # Expand dimensions for the network\n",
    "    normalized_input_image = np.expand_dims(image, 0)# (1,270, 480, 3)\n",
    "    return normalized_input_image\n",
    "\n",
    "def restructure_image(predicted_tensor):\n",
    "    '''\n",
    "    output_image = restructure_image()\n",
    "    (1, 1080, 1920, 3)\n",
    "    '''\n",
    "    # Remove batch dimension \n",
    "    # (1, 1080, 1920, 3)-> (1080, 1920, 3)\n",
    "    output_image = np.squeeze(predicted_tensor, axis=0)  \n",
    "    # Post process\n",
    "    output_image = postprocess_image(output_image)\n",
    "    return output_image\n",
    "\n",
    "# Get model details\n",
    "def print_model_details(interpreter):\n",
    "    #print_model_details(interpreter)\n",
    "    # Get tensor details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(\"Input Details:\")\n",
    "    for detail in input_details:\n",
    "        print(f\"Name: {detail['name']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")\n",
    "    \n",
    "    print(\"\\nOutput Details:\")\n",
    "    for detail in output_details:\n",
    "        print(f\"Name: {detail['name']}, Shape: {detail['shape']}, dtype: {detail['dtype']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10319b60-1277-4c9c-b158-20fbb22e88b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = 'input_880_480.jpg'\n",
    "normalized_input_image = digest_input(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10b2f3b1-d643-42d9-b079-8a0a89f68593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In:Shape: [  1 270 480   3], dtype: <class 'numpy.float32'> - Out: Shape:[1 1080 1920 3], dtype: <class 'numpy.float32'>\n",
    "model_path = 'models/evsrnet_x4.tflite'\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e84f5c06-e5f8-45dd-a0cc-e52040c28cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf time 0.20264339447021484\n"
     ]
    }
   ],
   "source": [
    "# Set the input tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "interpreter.set_tensor(input_index, normalized_input_image)\n",
    "\n",
    "# Run inference\n",
    "start = time.time()\n",
    "interpreter.invoke()\n",
    "end = time.time()\n",
    "print(f\"inf time {end-start}\")\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "output_data = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e7ca7d75-432d-430b-a41d-252abe407fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_image = restructure_image(output_data)\n",
    "output_path = 'output_Python.jpg'\n",
    "output_image.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370d74a-a350-4cfb-8e69-7cf384c6e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
